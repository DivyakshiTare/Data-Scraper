{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOESDx0ET7V8s9H5+/tt0pX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivyakshiTare/Data-Scraper/blob/main/Data_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slFsY9ZMrW27",
        "outputId": "288216b3-00fa-48c7-d19c-5bf88ebbe61e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected 284 filings\n",
            "Data saved to output/sec_filings_20241220.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import logging\n",
        "from typing import List, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import urllib.parse\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CompanyFiling:\n",
        "    cik: str\n",
        "    company_name: str\n",
        "    filing_type: str\n",
        "    filing_date: str\n",
        "    filing_link: Optional[str] = None\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {k: v for k, v in self.__dict__.items() if v is not None}\n",
        "\n",
        "class EDGARCollector:\n",
        "    def __init__(self, email: str, rate_limit: float = 0.1):\n",
        "        \"\"\"\n",
        "        Initialize the SEC EDGAR collector\n",
        "\n",
        "        Args:\n",
        "            email: Email address for SEC request header\n",
        "            rate_limit: Minimum time between requests in seconds (SEC requires 0.1s)\n",
        "        \"\"\"\n",
        "        self.base_url = \"https://data.sec.gov/submissions\"\n",
        "        self.headers = {\n",
        "            'User-Agent': f'CompanyResearch research@{email}',\n",
        "        }\n",
        "        self.rate_limit = rate_limit\n",
        "        self.last_request = 0\n",
        "\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def _respect_rate_limit(self):\n",
        "        \"\"\"Ensure we don't exceed SEC's rate limits\"\"\"\n",
        "        now = time.time()\n",
        "        time_passed = now - self.last_request\n",
        "        if time_passed < self.rate_limit:\n",
        "            time.sleep(self.rate_limit - time_passed)\n",
        "        self.last_request = time.time()\n",
        "\n",
        "    def get_company_info(self, cik: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Get company information from SEC EDGAR\n",
        "\n",
        "        Args:\n",
        "            cik: Company's CIK number (SEC identifier)\n",
        "        \"\"\"\n",
        "        self._respect_rate_limit()\n",
        "\n",
        "        # Pad CIK to 10 digits\n",
        "        cik_padded = str(cik).zfill(10)\n",
        "\n",
        "        try:\n",
        "            response = requests.get(\n",
        "                f\"{self.base_url}/CIK{cik_padded}.json\",\n",
        "                headers=self.headers\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            self.logger.error(f\"Error fetching company info: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def search_companies(self, company_name: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Search for companies using the SEC company search\n",
        "        This is a simplified implementation that gets the first page of results\n",
        "        \"\"\"\n",
        "        self._respect_rate_limit()\n",
        "\n",
        "        search_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
        "        params = {\n",
        "            'company': company_name,\n",
        "            'owner': 'exclude',\n",
        "            'action': 'getcompany',\n",
        "            'output': 'atom'\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(search_url, params=params, headers=self.headers)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Parse the XML response to get CIKs\n",
        "            # This is a simplified implementation\n",
        "            companies = []\n",
        "            ciks = set()\n",
        "\n",
        "            # Extract CIKs from the response text\n",
        "            # Note: In a production environment, use proper XML parsing\n",
        "            for line in response.text.split('\\n'):\n",
        "                if 'CIK=' in line:\n",
        "                    cik = line.split('CIK=')[1].split('&')[0]\n",
        "                    if cik not in ciks:\n",
        "                        ciks.add(cik)\n",
        "                        company_info = self.get_company_info(cik)\n",
        "                        if company_info:\n",
        "                            companies.append(company_info)\n",
        "\n",
        "            return companies\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            self.logger.error(f\"Error searching companies: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def get_recent_filings(self, cik: str, filing_types: List[str] = None) -> List[CompanyFiling]:\n",
        "        \"\"\"\n",
        "        Get recent filings for a company\n",
        "\n",
        "        Args:\n",
        "            cik: Company's CIK number\n",
        "            filing_types: List of filing types to include (e.g., ['10-K', '10-Q'])\n",
        "        \"\"\"\n",
        "        company_info = self.get_company_info(cik)\n",
        "        if not company_info:\n",
        "            return []\n",
        "\n",
        "        filings = []\n",
        "        recent_filings = company_info.get('filings', {}).get('recent', {})\n",
        "\n",
        "        if not recent_filings:\n",
        "            return []\n",
        "\n",
        "        # Get the filing information\n",
        "        for i in range(len(recent_filings.get('accessionNumber', []))):\n",
        "            filing_type = recent_filings['form'][i]\n",
        "\n",
        "            # Skip if not in requested filing types\n",
        "            if filing_types and filing_type not in filing_types:\n",
        "                continue\n",
        "\n",
        "            filing = CompanyFiling(\n",
        "                cik=cik,\n",
        "                company_name=company_info.get('name', ''),\n",
        "                filing_type=filing_type,\n",
        "                filing_date=recent_filings['filingDate'][i],\n",
        "                filing_link=self._construct_filing_link(\n",
        "                    recent_filings['accessionNumber'][i],\n",
        "                    recent_filings.get('primaryDocument', [''])[i]\n",
        "                )\n",
        "            )\n",
        "            filings.append(filing)\n",
        "\n",
        "        return filings\n",
        "\n",
        "    def _construct_filing_link(self, accession_number: str, primary_doc: str) -> str:\n",
        "        \"\"\"Construct the SEC archive URL for a filing\"\"\"\n",
        "        acc_no = accession_number.replace('-', '')\n",
        "        return f\"https://www.sec.gov/Archives/edgar/data/{acc_no}/{primary_doc}\"\n",
        "\n",
        "    def collect_company_data(self, search_terms: List[str], filing_types: List[str] = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Collect company data and recent filings based on search terms\n",
        "\n",
        "        Args:\n",
        "            search_terms: List of company names or keywords to search\n",
        "            filing_types: List of filing types to include\n",
        "        \"\"\"\n",
        "        all_filings = []\n",
        "\n",
        "        for term in search_terms:\n",
        "            self.logger.info(f\"Searching for: {term}\")\n",
        "            companies = self.search_companies(term)\n",
        "\n",
        "            for company in companies:\n",
        "                cik = company.get('cik', '')\n",
        "                if cik:\n",
        "                    filings = self.get_recent_filings(cik, filing_types)\n",
        "                    all_filings.extend(filings)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame([filing.to_dict() for filing in all_filings])\n",
        "\n",
        "        if not df.empty:\n",
        "            # Convert dates to datetime\n",
        "            df['filing_date'] = pd.to_datetime(df['filing_date'])\n",
        "\n",
        "            # Remove duplicates\n",
        "            df = df.drop_duplicates()\n",
        "\n",
        "            # Sort by filing date\n",
        "            df = df.sort_values('filing_date', ascending=False)\n",
        "\n",
        "        return df\n",
        "\n",
        "def main():\n",
        "    # Example usage\n",
        "    collector = EDGARCollector(\n",
        "        email=\"divyakshitare09@gmail.com\",  # Replace with your email\n",
        "        rate_limit=0.1  # SEC requires 100ms between requests\n",
        "    )\n",
        "\n",
        "    # Example: Collect recent 10-K and 10-Q filings for technology companies\n",
        "    df = collector.collect_company_data(\n",
        "        search_terms=[\"software\", \"technology\"],\n",
        "        filing_types=['10-K', '10-Q']\n",
        "    )\n",
        "\n",
        "    # Save results\n",
        "    output_dir = Path(\"output\")\n",
        "    output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    output_file = output_dir / f\"sec_filings_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"Collected {len(df)} filings\")\n",
        "    print(f\"Data saved to {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}